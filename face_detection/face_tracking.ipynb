{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face tracking pipeline\n",
    "\n",
    "The following example illustrates how to use the `facenet_pytorch` python package to perform face detection and tracking on an image dataset using MTCNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "import torch\n",
    "import numpy as np\n",
    "import mmcv, cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine if an nvidia GPU is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Running on device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define MTCNN module\n",
    "\n",
    "Note that, since MTCNN is a collection of neural nets and other code, the device must be passed in the following way to enable copying of objects when needed internally.\n",
    "\n",
    "See `help(MTCNN)` for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mtcnn = MTCNN(keep_all=True, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get a sample video\n",
    "\n",
    "We begin by loading a video with some faces in it. The `mmcv` PyPI package by mmlabs is used to read the video frames (it can be installed with `pip install mmcv`). Frames are then converted to PIL images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"video.mp4\" controls  width=\"640\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video = mmcv.VideoReader('video.mp4')\n",
    "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "\n",
    "display.Video('video.mp4', width=640)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run video through MTCNN\n",
    "\n",
    "We iterate through each frame, detect faces, and draw their bounding boxes on the video frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking frame: 105\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "frames_tracked = []\n",
    "for i, frame in enumerate(frames):\n",
    "    print('\\rTracking frame: {}'.format(i + 1), end='')\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, _ = mtcnn.detect(frame)\n",
    "    # Draw faces\n",
    "    frame_draw = frame.copy()\n",
    "    draw = ImageDraw.Draw(frame_draw)\n",
    "    for box in boxes:\n",
    "        draw.rectangle(box.tolist(), outline=(255, 0, 0), width=6)\n",
    "    \n",
    "    # Add to frame list\n",
    "    frames_tracked.append(frame_draw.resize((640, 360), Image.BILINEAR))\n",
    "print('\\nDone')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = display.display(frames_tracked[0], display_id=True)\n",
    "i = 1\n",
    "try:\n",
    "    while True:\n",
    "        d.update(frames_tracked[i % len(frames_tracked)])\n",
    "        i += 1\n",
    "except KeyboardInterrupt:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tracked video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = frames_tracked[0].size\n",
    "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
    "video_tracked = cv2.VideoWriter('video_tracked.mp4', fourcc, 25.0, dim)\n",
    "for frame in frames_tracked:\n",
    "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
    "video_tracked.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
